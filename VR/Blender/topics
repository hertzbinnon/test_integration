### How to use ,examples:
https://blenderartists.org/
https://www.bilibili.com/video/av59983022

https://www.blenderguru.com/tutorials/couch-william

https://www.blender3darchitect.com/vr/pantry-island-360-render-architecture-blender/ 

https://blender.stackexchange.com/questions/34054/ffmpeg-from-inside-blender

###Develement 
https://wiki.blender.org/wiki/Source/File_Structure # Source Code files layout 

https://archive.blender.org/wiki/index.php/Dev:Source/ # Old archive

https://wiki.blender.org/wiki/User:Severin/GSoC-2019/Final_Report # Openxr VR
https://skarredghost.com/2020/04/10/how-to-blender-vr/

https://wiki.blender.org/wiki/Tools/Tips_for_Coding_Blender

https://www.janwalter.org/jekyll/blender/rust/blendinfo/2019/05/28/blend_info.html
https://www.rs-pbrt.org/blog/

### remove gameengine from 2.8 
https://blender.stackexchange.com/questions/106972/what-will-happen-with-blender-2-8-game-engine
https://upbge.org/

### Build
make debug #debug version

make  # release version

###################################################################################################
Open Window --> WM_check(C) blender-git/blender/source/blender/windowmanager/intern/wm_files.c

draw        --> wm_window_swap_buffers() blender-git/blender/source/blender/windowmanager/intern/wm_window.c

[1]. ghost--> [Stands for General Handy Operating System Toolkit.
   This library abstracts platform specific operations. So we can avoid using OSX/Win32/X11 API calls in the rest of Blender's code.

   It handles window management actions, the OpenGL context and reading events from the mouse and keyboard, it also supports less common input devices such as a tablet or NDOF device.]


################################################################################################### 
#blender camera config
https://www.douban.com/note/733577494/
#blender canvas
https://www.bilibili.com/video/av712093069
#blender camera operater 
https://www.bilibili.com/video/BV1CT4y1J7uL?from=search&seid=3650353677332472280
# script control camera
http://www.voidcn.com/article/p-zaikulge-buy.html

## blender图片编辑教程
https://www.bilibili.com/video/av412820507
# multicamera switch animation
https://www.bilibili.com/video/av76391297/
##360 video build
https://docs.blender.org/manual/en/latest/render/cycles/object_settings/cameras.html
https://www.veer.tv/blog/blender-tutorial-how-to-render-a-3d-vr-video-from-blender/
https://veer.tv/blog/capture-360-photos-videos-from-modelling-tool-game-engine/
https://haokan.baidu.com/v?pd=wisenatural&vid=1553244016335797716

https://blog.csdn.net/weixin_44546865/article/details/90380893

#命令行
https://docs.blender.org/manual/zh-hans/dev/advanced/command_line/render.html

https://www.uegeek.com/190320-3d03-blender-intro.html

#后台
https://docs.blender.org/manual/zh-hans/dev/advanced/scripting/security.html


#版权
http://www.bgteach.com/article/153

# Render 360 using eevee
https://www.oneminutevideotutorials.com/2020/08/20/how-to-render-a-stereoscopic-360-animation-from-blender-eevee/
https://www.bilibili.com/video/BV1LU4y1V7Qi/
##
How to render a stereoscopic 360 animation from Blender EEVEE
Rendering out stereo 360 from Blender EEVEE is actually pretty easy thanks to the new eeVR addon.

Here are the steps to take if you want to do an equirectangular render from EEVEE:

1. Download the eeVR addon from Github: https://github.com/EternalTrail/eeVR
2. Install the VRRenderer.py file using the normal addon installation process
3. Open the new “Testing” tab in the addons and activate eeVR there
4. Open the eeVR settings in the viewport view3d-settings area (the panel that opens with the N-key)
5. Set field of view to 360
6. Go to the render settings (the symbol with a printer icon) and enable stereoscopy
7. Model your scene and remember to save it.
8. Hit “render animation” from the eeVR panel.
9. You will soon have a folder full of stereoscopic 360 PNG images in the folder that contains your Blender file.

If you want to convert the PNG files into an Oculus Quest compatible file, you can use this FFMPEG command (frame%6d means that the filenames have the word frame followed by 6 digits):

ffmpeg -i frame%6d.png -framerate 30 -c:v libx265 -preset slow -crf 17 -vf "scale=4096x4096" -pix_fmt yuv420p -an -movflags faststart -r 30 "output_sideload_4096_h265_crf17.mp4"

That script was adapted from https://echeng.com/articles/encoding-for-oculus-media-studio/

If you want to upload the video to Youtube, simply use this Metadata Injector before uploading:

https://github.com/google/spatial-media/releases/tag/v2.0

After injecting the file with the correct metadata, Youtube should understand the file as stereoscopic 360 video. Note that the processing of the file might take some time and it might not work correctly as 360 video before the processing for that is ready.

# https://monochrome.sutic.nu/2018/02/14/360-video-with-blender.html


https://blender.stackexchange.com/questions/89335/live-real-time-video-compositing-onto-a-virtual-studio
https://www.bilibili.com/video/BV1fv411B7eb/?spm_id_from=pageDriver

